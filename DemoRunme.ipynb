{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pickle\n",
    "from scipy.stats import skew\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import UserInputs2WorkingForm\n",
    "from functions import GetTrainingData\n",
    "from functions import GetSplitTrainingData\n",
    "from functions import GetAllModelsForComparison\n",
    "from functions import GetTESTDataFrameNames\n",
    "from functions import getTESTDataFrame\n",
    "from functions import getBarPlot\n",
    "from functions import getGraphs\n",
    "from functions import getPlot\n",
    "from functions import GenerateComparisonResultFiles\n",
    "from functions import FeatureComparison\n",
    "from functions import GetOnlyTwoModelsForComparison\n",
    "from functions import GetFinalEightModelsForComparison\n",
    "from functions import GetFinalModelForComparison\n",
    "from functions import TrainModel\n",
    "from functions import PredictModel\n",
    "from functions import PredictProbModel\n",
    "from functions import GenerateIMSDictionary\n",
    "from functions import GenerateTrainingFile\n",
    "from functions import Magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate a Training Data File\n",
    "\"\"\"\n",
    "GenerateTrainingFile(\"NotNormalized.csv\")\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'dataset' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cdd4cb21b5e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerateIMSDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2003.10.22.12.06.24'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"TEST.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetTrainingData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUserInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mXXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYYY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetTrainingData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/9 2019 Fall/ECEN 403/Programming/ProgramsForDemo/DemoEarly/functions.py\u001b[0m in \u001b[0;36mGetTrainingData\u001b[0;34m(UserInput)\u001b[0m\n\u001b[1;32m   1096\u001b[0m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'dataset' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Veryifies the new generate training file works as before\n",
    "\"\"\"\n",
    "UserInput = GenerateIMSDictionary('2003.10.22.12.06.24',\"DELETE.csv\",os.getcwd())\n",
    "Test = GenerateIMSDictionary('2003.10.22.12.06.24',\"TEST.csv\",os.getcwd())\n",
    "\n",
    "XX, YY, ALL = GetTrainingData(UserInput)\n",
    "XXX, YYY, ALL1 = GetTrainingData(Test)\n",
    "\n",
    "print(np.array_equal(XX,XXX))\n",
    "print(np.array_equal(YY,YYY))\n",
    "print(np.array_equal(ALL,ALL1))\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "'Simulate' receiving GUI Input\n",
    "\"\"\"\n",
    "UserInput = GenerateIMSDictionary('2003.10.22.12.06.24',\"NoNegatives.csv\",os.getcwd())\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get Training data sets\n",
    "\"\"\"\n",
    "X_train, X_test, Y_train, Y_test = GetSplitTrainingData(UserInput)\n",
    "Xall_train, Yall_train, dataset = GetTrainingData(UserInput)\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Comparisons\n",
    "\"\"\"\n",
    "\n",
    "#Quick Demonstration\n",
    "models = GetOnlyTwoModelsForComparison(X_train,Y_train)\n",
    "\n",
    "#Initial\n",
    "#models = GetAllModelsForComparison(X_train,Y_train)\n",
    "\n",
    "#Min Samples Comparsion\n",
    "\"\"\"\n",
    "for x in range(1,50,2):\n",
    "    print(x)\n",
    "    models = GetFinalEightModelsForComparison(X_train,Y_train,MinSampleSplit=x)\n",
    "    results,string,string1,time,fig = FeatureComparison(models,X_train, X_test, Y_train, Y_test,UserInput)\n",
    "    Graphname = 'GraphMinSamples' + str(x) + '.pdf'\n",
    "    Timename = 'TimeMinSamples' + str(x) + '.txt'\n",
    "    Scoringname = 'ScoreMinSamples' + str(x) + '.txt'\n",
    "    GenerateComparisonResultFiles(results,string,string1,time,fig,str1 = Graphname,\\\n",
    "                                  str2 = Timename,str3 = \"NoGraphs.txt\",str4 = Scoringname)\n",
    "\"\"\"\n",
    "\n",
    "#Number of Estimators Comparison\n",
    "\"\"\"\n",
    "for x in range(10,1010,10):\n",
    "    print(x)\n",
    "    models = GetFinalModelForComparison(X_train,Y_train, MinSampleSplit=10, Nestimators = x)\n",
    "    results,string,string1,time,fig = FeatureComparison(models,X_train, X_test, Y_train, Y_test,UserInput)\n",
    "    Graphname = 'GraphMinSamples' + str(x) + '.pdf'\n",
    "    Timename = 'TimeMinSamples' + str(x) + '.txt'\n",
    "    Scoringname = 'ScoreMinSamples' + str(x) + '.txt'\n",
    "    GenerateComparisonResultFiles(results,string,string1,time,fig,str1 = Graphname,\\\n",
    "                                  str2 = Timename,str3 = \"NoGraphs.txt\",str4 = Scoringname)\n",
    "\"\"\"\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demonstrate Selected Model's results using\n",
    "classification report\n",
    "\"\"\"\n",
    "#Test on the split model\n",
    "classifier0 = TrainModel(X_train, Y_train)\n",
    "Y_pred,Y_pred_string = PredictModel(classifier0,X_test)\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print('\\nfinished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train on Final Model using all of the training data\n",
    "\n",
    "Final Model:\n",
    "RandomForestClassifier(min_samples_split = 10 ,n_estimators = 200)\n",
    "{   'bootstrap': True, \n",
    "    'class_weight': None, \n",
    "    'criterion': 'gini', \n",
    "    'max_depth': None, \n",
    "    'max_features': 'auto', \n",
    "    'max_leaf_nodes': None, \n",
    "    'min_impurity_decrease': 0.0, \n",
    "    'min_impurity_split': None, \n",
    "    'min_samples_leaf': 1, \n",
    "    'min_samples_split': 10, \n",
    "    'min_weight_fraction_leaf': 0.0, \n",
    "    'n_estimators': 200, \n",
    "    'n_jobs': 1, \n",
    "    'oob_score': False, \n",
    "    'random_state': None, \n",
    "    'verbose': 0, \n",
    "    'warm_start': False}\n",
    "\"\"\"\n",
    "classifier = TrainModel(Xall_train, Yall_train)\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Using Pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate a File That needs to be question\n",
    "\"\"\"\n",
    "X_in_question = getTESTDataFrame(UserInput)\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "classifier2 = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prediction Results\n",
    "Compared Both Current and Saved Models\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "X_verify = X_in_question.values[:,0:(X_in_question.shape[1]-1)]\n",
    "\n",
    "prediction,prediction_string = PredictModel(classifier,X_verify)\n",
    "prediction_proba = PredictProbModel(classifier,X_verify)\n",
    "print('Current Model:\\n')\n",
    "print(prediction)\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "prediction,prediction_string = PredictModel(classifier2,X_verify)\n",
    "prediction_proba = PredictProbModel(classifier2,X_verify)\n",
    "print('\\n')\n",
    "print('Loaded Model:\\n')\n",
    "print(prediction)\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BEGIN Feature Reduction\n",
    "\n",
    "\"\"\"\n",
    "m = classifier.feature_importances_\n",
    "m1 = GetTESTDataFrameNames(UserInput)\n",
    "Z = [x for _,x in sorted(zip(m,m1))]\n",
    "Z1 = sorted(m)\n",
    "fig = getBarPlot(Z1[-10:],Z[-10:],\"Relative Importance\",\"FINAL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reduce Features on the Training Data and Test Data frame\n",
    "\"\"\"\n",
    "filename = 'NoNegatives.csv'\n",
    "dataset = pd.read_csv(filename,header = 0,index_col = 0)\n",
    "StateTrain = dataset['State'].values\n",
    "ReducedFeatureTrainingData = {\n",
    "    '2':  dataset[['RMS','FTF']],\n",
    "    '3':  dataset[['RMS','FTF','Max ABS']],\n",
    "    '4':  dataset[['RMS','FTF','Max ABS','Skew']],\n",
    "    '5':  dataset[['RMS','FTF','Max ABS','Skew','FFT Amp @ Peak 4']],\n",
    "    '6':  dataset[['RMS','FTF','Max ABS','Skew','FFT Amp @ Peak 4','Autocorrelate Time @ Peak 5']],\n",
    "    '7':  dataset[['RMS','FTF','Max ABS','Skew','FFT Amp @ Peak 4','Autocorrelate Time @ Peak 5','PSD Frq @ Peak 5']],\n",
    "    '8':  dataset[['RMS','FTF','Max ABS','Skew','FFT Amp @ Peak 4','Autocorrelate Time @ Peak 5','PSD Frq @ Peak 5','FFT Frq @ Peak 1']],\n",
    "    '9':  dataset[['RMS','FTF','Max ABS','Skew','FFT Amp @ Peak 4','Autocorrelate Time @ Peak 5','PSD Frq @ Peak 5','FFT Frq @ Peak 1','Min']],\n",
    "    '10': dataset[['RMS','FTF','Max ABS','Skew','FFT Amp @ Peak 4','Autocorrelate Time @ Peak 5','PSD Frq @ Peak 5','FFT Frq @ Peak 1','Min','PSD Frq @ Peak 1']],\n",
    "    '3a': dataset[['RMS','Max ABS','Skew']],\n",
    "    '4a': dataset[['RMS','Max ABS','Skew','Max']],\n",
    "    '5a': dataset[['RMS','Max ABS','Skew','Max','Min']],\n",
    "    'all': dataset.drop(columns=['State'])\n",
    "}\n",
    "\n",
    "validation_size = 0.20\n",
    "seed = 6\n",
    "\n",
    "for set in ReducedFeatureTrainingData:\n",
    "    FeatureTrain = ReducedFeatureTrainingData[set].values\n",
    "    xtrain, xtest, ytrain, ytest = model_selection.train_test_split(FeatureTrain, StateTrain, test_size=validation_size, random_state=seed) \n",
    "\n",
    "    Classifier = RandomForestClassifier(min_samples_split = 10 ,n_estimators = 200).fit(xtrain,ytrain)\n",
    "    ypred,ypredstring = PredictModel(Classifier,xtest)\n",
    "    print('Feature Number ({}):'.format(set))\n",
    "    print(classification_report(ytest,ypred))\n",
    "    print('\\n')\n",
    "    \n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BEGIN CODE FOR ACTUAL DATA\n",
    "\n",
    "This will be validated using strictly the RMS, Skew values\n",
    "\n",
    "This section generates and saves the Machine Learning model\n",
    "\n",
    "This section is not to be run on the actual microcontroller. \n",
    "Will through an error is the training data NoNegatives.csv is not present\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "filename = 'NoNegatives.csv'\n",
    "dataset = pd.read_csv(filename,header = 0,index_col = 0)\n",
    "dataset1 = dataset[['RMS','Skew']]\n",
    "FeatureTrain = dataset1.values\n",
    "StateTrain = dataset['State'].values\n",
    "\n",
    "\n",
    "Classifier = RandomForestClassifier(min_samples_split = 10 ,n_estimators = 200).fit(FeatureTrain,StateTrain)\n",
    "\n",
    "filename = 'ShortModel.sav'\n",
    "pickle.dump(Classifier, open(filename, 'wb'))\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Working on actaul data\n",
    "\"\"\"\n",
    "\n",
    "#Import Raw Data\n",
    "filename = 'AccelerometerActualData.csv'\n",
    "dataset = pd.read_csv(filename, header = None, index_col = False)\n",
    "dataset.rename(columns={0: \"Time\", 1: \"Value\"}, inplace = True)\n",
    "print(dataset.head(20))\n",
    "\n",
    "#Prepare Raw Data\n",
    "i = 0\n",
    "time = []\n",
    "amp = []\n",
    "while i < len(dataset['Time'].values):\n",
    "    i += 1\n",
    "    \n",
    "    if dataset['Time'].values[i] == 0 and dataset['Value'].values[i] == 0:\n",
    "        break\n",
    "    else:\n",
    "        time.append(dataset['Time'].values[i])\n",
    "        amp.append(dataset['Value'].values[i])\n",
    "            \n",
    "#Normalize\n",
    "amp = amp - np.mean(amp)\n",
    "mag_amp = Magnitude(amp)\n",
    "amp = amp / mag_amp\n",
    "\n",
    "#Set Up Test Array\n",
    "Test_RMS = np.mean(amp**2)\n",
    "Test_Skew = skew(amp)\n",
    "Test_Combined = np.column_stack((Test_RMS,Test_Skew))\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved model\n",
    "ClassifierShort = pickle.load(open('ShortModel.sav', 'rb'))\n",
    "\n",
    "#Predict model\n",
    "prediction,prediction_string = PredictModel(ClassifierShort,Test_Combined)\n",
    "prediction_proba = PredictProbModel(ClassifierShort,Test_Combined)\n",
    "print(prediction)\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demonstrate Graphing Capabilites \n",
    "Combines the GraphDemonstration graphs for a single sample\n",
    "\"\"\"\n",
    "figs = getGraphs(UserInput)\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Graph for Brendan\"\n",
    "figs = []\n",
    "filename = 'NoNegatives.csv'\n",
    "dataset = pd.read_csv(filename,header = 0,index_col = 0)\n",
    "figs.append(getPlot(dataset.index[0:2155],dataset[\"RMS\"][0:2155].values,\"Sample # (Bearing 1, X)\",\"RMS\",\"RMS\"))\n",
    "figs.append(getPlot(dataset.index[2156:4311],dataset[\"RMS\"][2156:4311].values,\"Sample # (Bearing 2, X)\",\"RMS\",\"RMS\"))\n",
    "figs.append(getPlot(dataset.index[4312:6467],dataset[\"RMS\"][4312:6467].values,\"Sample # (Bearing 3, X)\",\"RMS\",\"RMS\"))\n",
    "figs.append(getPlot(dataset.index[6468:8623],dataset[\"RMS\"][6468:8623].values,\"Sample # (Bearing 4, X)\",\"RMS\",\"RMS\"))\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
